from surprise import Dataset, Reader, KNNBasic, dump
from surprise.model_selection import train_test_split
import pandas as pd
import os
from collections import Counter,defaultdict
import random
from tqdm import tqdm
import pandas as pd
import random
from collections import defaultdict

def analyze_data(df):
    """Veri setini detaylÄ± analiz eder"""
    print("\nğŸ“Š Veri Seti Ä°statistikleri:")
    print(f"âœ… Toplam satÄ±r sayÄ±sÄ±: {len(df):,}")
    print(f"âœ… Benzersiz kullanÄ±cÄ± sayÄ±sÄ±: {df['User-ID'].nunique():,}")
    print(f"âœ… Benzersiz kitap sayÄ±sÄ±: {df['ISBN'].nunique():,}")
    
    print("\nâ­ Rating DaÄŸÄ±lÄ±mÄ±:")
    print(df['Book-Rating'].value_counts().sort_index())
    
    print("\nğŸ‘¥ KullanÄ±cÄ± BaÅŸÄ±na Rating SayÄ±sÄ±:")
    print(df['User-ID'].value_counts().describe())
    
    print("\nğŸ“š Kitap BaÅŸÄ±na Rating SayÄ±sÄ±:")
    print(df['ISBN'].value_counts().describe())



def analyze_user_similarity():
    df = pd.read_csv("newbookdata.csv", dtype={'User-ID': str, 'ISBN': str})
    
    print("\nğŸ” KullanÄ±cÄ± bazlÄ± ortak kitap okuma analizi baÅŸlatÄ±lÄ±yor...\n")

    user_books = df.groupby("User-ID")["ISBN"].apply(set).to_dict()
    target_users = random.sample(list(user_books.keys()), 500)

    for target_user in tqdm(target_users, desc="ğŸ”„ KullanÄ±cÄ±lar analiz ediliyor"):
        target_set = user_books[target_user]
        result = []
        for other_user, other_set in user_books.items():
            if other_user == target_user:
                continue
            common_books = target_set & other_set
            if len(common_books) >= 2:
                result.append((other_user, len(common_books)))
        result.sort(key=lambda x: x[1], reverse=True)
        print(f"\nğŸ‘¤ KullanÄ±cÄ± {target_user}, aÅŸaÄŸÄ±daki kullanÄ±cÄ±larla ortak kitaplar okumuÅŸ:")
        for uid, count in result[:5]:
            print(f"   - {uid} ile {count} ortak kitap")

def analyze_item_similarity():
    df = pd.read_csv("newbookdata.csv", dtype={'User-ID': str, 'ISBN': str})
    
    print("\nğŸ“š Kitap bazlÄ± ortak kullanÄ±cÄ± okuma analizi baÅŸlatÄ±lÄ±yor...\n")

    isbn_users = df.groupby("ISBN")["User-ID"].apply(set).to_dict()
    user_books = df.groupby("User-ID")["ISBN"].apply(set).to_dict()

    target_isbns = random.sample(list(isbn_users.keys()), 500)

    for target_isbn in tqdm(target_isbns, desc="ğŸ”„ Kitaplar analiz ediliyor"):
        users = isbn_users[target_isbn]
        book_counter = defaultdict(int)
        
        for user in users:
            books = user_books.get(user, set())
            for book in books:
                if book != target_isbn:
                    book_counter[book] += 1
        
        similar_books = sorted(book_counter.items(), key=lambda x: x[1], reverse=True)[:5]
        print(f"\nğŸ“– Kitap {target_isbn} (okuyan sayÄ±sÄ±: {len(users)}), ÅŸu kitaplarla birlikte sÄ±kÃ§a okunmuÅŸ:")
        for isbn, count in similar_books:
            print(f"   - {isbn}: {count} kez birlikte okunmuÅŸ")



def reduce_users_in_cleaned_data(target_user_count=5000):

    """    - Benzersiz kullanÄ±cÄ± sayÄ±sÄ±nÄ± azaltÄ±r (target_user_count'a kadar)
    - Veri sayÄ±sÄ±nÄ± korur
    - Ã‡akÄ±ÅŸan ratinglerde rastgele birini seÃ§er
    - Sonucu yeni bir CSV'ye kaydeder
    """
    # Veriyi yÃ¼kle
    df = pd.read_csv("models/cleaned_bookdata.csv", dtype={'User-ID': str, 'ISBN': str})
    
    print(f"\nğŸ”§ Ä°ÅŸlem baÅŸlÄ±yor...")
    print(f"Orijinal veri sayÄ±sÄ±: {len(df):,}")
    print(f"Orijinal benzersiz kullanÄ±cÄ±: {df['User-ID'].nunique():,}")
    print(f"Hedef benzersiz kullanÄ±cÄ±: {target_user_count:,}")

    # 1. KullanÄ±cÄ±larÄ± okuma sayÄ±larÄ±na gÃ¶re grupla
    user_book_counts = df['User-ID'].value_counts()
    all_users = user_book_counts.index.tolist()
    
    # 2. En aktif kullanÄ±cÄ±larÄ± seÃ§ (hedef sayÄ± kadar)
    selected_users = all_users[:target_user_count]
    
    # 3. Kalan kullanÄ±cÄ±larÄ± rastgele seÃ§ilmiÅŸ kullanÄ±cÄ±lara ata
    user_mapping = {user: user for user in selected_users}
    for user in all_users[target_user_count:]:
        user_mapping[user] = random.choice(selected_users)
    
    # 4. KullanÄ±cÄ± ID'lerini gÃ¼ncelle
    df['User-ID'] = df['User-ID'].map(user_mapping)
    
    # 5. AynÄ± kullanÄ±cÄ±-kitap Ã§iftleri iÃ§in rastgele bir rating seÃ§
    df = df.sample(frac=1).drop_duplicates(['User-ID', 'ISBN'], keep='first')
    
    # 6. SonuÃ§larÄ± kaydet
    output_path = "newbookdata.csv"
    df.to_csv(output_path, index=False)
    
    print(f"\nâœ… Ä°ÅŸlem tamamlandÄ±!")
    print(f"Yeni veri sayÄ±sÄ±: {len(df):,}")
    print(f"Yeni benzersiz kullanÄ±cÄ±: {df['User-ID'].nunique():,}")
    print(f"Yeni benzersiz kitap: {df['ISBN'].nunique():,}")
    print(f"SonuÃ§lar '{output_path}' dosyasÄ±na kaydedildi.")


if __name__ == '__main__':
  
    analyze_user_similarity()
    analyze_item_similarity()

